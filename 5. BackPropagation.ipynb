{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4da963c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************\n",
      "iteration: 0 :::: [[ 0.0720921  -0.94906383]]\n",
      "###output######## [[0.9279079  0.94906383]]\n",
      "**********************\n",
      "iteration: 1 :::: [[ 0.07203592 -0.94865304]]\n",
      "###output######## [[0.92796408 0.94865304]]\n",
      "**********************\n",
      "iteration: 2 :::: [[ 0.07197988 -0.94823618]]\n",
      "###output######## [[0.92802012 0.94823618]]\n",
      "**********************\n",
      "iteration: 3 :::: [[ 0.07192399 -0.94781309]]\n",
      "###output######## [[0.92807601 0.94781309]]\n",
      "**********************\n",
      "iteration: 4 :::: [[ 0.07186825 -0.94738367]]\n",
      "###output######## [[0.92813175 0.94738367]]\n",
      "**********************\n",
      "iteration: 5 :::: [[ 0.07181265 -0.94694777]]\n",
      "###output######## [[0.92818735 0.94694777]]\n",
      "**********************\n",
      "iteration: 6 :::: [[ 0.07175721 -0.94650525]]\n",
      "###output######## [[0.92824279 0.94650525]]\n",
      "**********************\n",
      "iteration: 7 :::: [[ 0.0717019  -0.94605598]]\n",
      "###output######## [[0.9282981  0.94605598]]\n",
      "**********************\n",
      "iteration: 8 :::: [[ 0.07164675 -0.9455998 ]]\n",
      "###output######## [[0.92835325 0.9455998 ]]\n",
      "**********************\n",
      "iteration: 9 :::: [[ 0.07159173 -0.94513658]]\n",
      "###output######## [[0.92840827 0.94513658]]\n",
      "**********************\n",
      "iteration: 10 :::: [[ 0.07153687 -0.94466616]]\n",
      "###output######## [[0.92846313 0.94466616]]\n",
      "**********************\n",
      "iteration: 11 :::: [[ 0.07148214 -0.94418838]]\n",
      "###output######## [[0.92851786 0.94418838]]\n",
      "**********************\n",
      "iteration: 12 :::: [[ 0.07142756 -0.94370307]]\n",
      "###output######## [[0.92857244 0.94370307]]\n",
      "**********************\n",
      "iteration: 13 :::: [[ 0.07137313 -0.94321009]]\n",
      "###output######## [[0.92862687 0.94321009]]\n",
      "**********************\n",
      "iteration: 14 :::: [[ 0.07131884 -0.94270924]]\n",
      "###output######## [[0.92868116 0.94270924]]\n",
      "**********************\n",
      "iteration: 15 :::: [[ 0.07126469 -0.94220037]]\n",
      "###output######## [[0.92873531 0.94220037]]\n",
      "**********************\n",
      "iteration: 16 :::: [[ 0.07121068 -0.94168329]]\n",
      "###output######## [[0.92878932 0.94168329]]\n",
      "**********************\n",
      "iteration: 17 :::: [[ 0.07115681 -0.94115781]]\n",
      "###output######## [[0.92884319 0.94115781]]\n",
      "**********************\n",
      "iteration: 18 :::: [[ 0.07110309 -0.94062375]]\n",
      "###output######## [[0.92889691 0.94062375]]\n",
      "**********************\n",
      "iteration: 19 :::: [[ 0.0710495  -0.94008092]]\n",
      "###output######## [[0.9289505  0.94008092]]\n",
      "**********************\n",
      "iteration: 20 :::: [[ 0.07099606 -0.9395291 ]]\n",
      "###output######## [[0.92900394 0.9395291 ]]\n",
      "**********************\n",
      "iteration: 21 :::: [[ 0.07094276 -0.93896809]]\n",
      "###output######## [[0.92905724 0.93896809]]\n",
      "**********************\n",
      "iteration: 22 :::: [[ 0.0708896  -0.93839769]]\n",
      "###output######## [[0.9291104  0.93839769]]\n",
      "**********************\n",
      "iteration: 23 :::: [[ 0.07083657 -0.93781767]]\n",
      "###output######## [[0.92916343 0.93781767]]\n",
      "**********************\n",
      "iteration: 24 :::: [[ 0.07078369 -0.93722781]]\n",
      "###output######## [[0.92921631 0.93722781]]\n",
      "**********************\n",
      "iteration: 25 :::: [[ 0.07073094 -0.93662788]]\n",
      "###output######## [[0.92926906 0.93662788]]\n",
      "**********************\n",
      "iteration: 26 :::: [[ 0.07067833 -0.93601765]]\n",
      "###output######## [[0.92932167 0.93601765]]\n",
      "**********************\n",
      "iteration: 27 :::: [[ 0.07062586 -0.93539685]]\n",
      "###output######## [[0.92937414 0.93539685]]\n",
      "**********************\n",
      "iteration: 28 :::: [[ 0.07057353 -0.93476526]]\n",
      "###output######## [[0.92942647 0.93476526]]\n",
      "**********************\n",
      "iteration: 29 :::: [[ 0.07052133 -0.93412259]]\n",
      "###output######## [[0.92947867 0.93412259]]\n",
      "**********************\n",
      "iteration: 30 :::: [[ 0.07046927 -0.9334686 ]]\n",
      "###output######## [[0.92953073 0.9334686 ]]\n",
      "**********************\n",
      "iteration: 31 :::: [[ 0.07041735 -0.932803  ]]\n",
      "###output######## [[0.92958265 0.932803  ]]\n",
      "**********************\n",
      "iteration: 32 :::: [[ 0.07036556 -0.93212552]]\n",
      "###output######## [[0.92963444 0.93212552]]\n",
      "**********************\n",
      "iteration: 33 :::: [[ 0.0703139  -0.93143586]]\n",
      "###output######## [[0.9296861  0.93143586]]\n",
      "**********************\n",
      "iteration: 34 :::: [[ 0.07026238 -0.93073371]]\n",
      "###output######## [[0.92973762 0.93073371]]\n",
      "**********************\n",
      "iteration: 35 :::: [[ 0.070211   -0.93001879]]\n",
      "###output######## [[0.929789   0.93001879]]\n",
      "**********************\n",
      "iteration: 36 :::: [[ 0.07015975 -0.92929075]]\n",
      "###output######## [[0.92984025 0.92929075]]\n",
      "**********************\n",
      "iteration: 37 :::: [[ 0.07010863 -0.92854929]]\n",
      "###output######## [[0.92989137 0.92854929]]\n",
      "**********************\n",
      "iteration: 38 :::: [[ 0.07005764 -0.92779406]]\n",
      "###output######## [[0.92994236 0.92779406]]\n",
      "**********************\n",
      "iteration: 39 :::: [[ 0.07000679 -0.92702471]]\n",
      "###output######## [[0.92999321 0.92702471]]\n",
      "**********************\n",
      "iteration: 40 :::: [[ 0.06995607 -0.92624088]]\n",
      "###output######## [[0.93004393 0.92624088]]\n",
      "**********************\n",
      "iteration: 41 :::: [[ 0.06990548 -0.92544221]]\n",
      "###output######## [[0.93009452 0.92544221]]\n",
      "**********************\n",
      "iteration: 42 :::: [[ 0.06985502 -0.92462832]]\n",
      "###output######## [[0.93014498 0.92462832]]\n",
      "**********************\n",
      "iteration: 43 :::: [[ 0.0698047  -0.92379882]]\n",
      "###output######## [[0.9301953  0.92379882]]\n",
      "**********************\n",
      "iteration: 44 :::: [[ 0.0697545  -0.92295329]]\n",
      "###output######## [[0.9302455  0.92295329]]\n",
      "**********************\n",
      "iteration: 45 :::: [[ 0.06970443 -0.92209133]]\n",
      "###output######## [[0.93029557 0.92209133]]\n",
      "**********************\n",
      "iteration: 46 :::: [[ 0.06965449 -0.9212125 ]]\n",
      "###output######## [[0.93034551 0.9212125 ]]\n",
      "**********************\n",
      "iteration: 47 :::: [[ 0.06960468 -0.92031637]]\n",
      "###output######## [[0.93039532 0.92031637]]\n",
      "**********************\n",
      "iteration: 48 :::: [[ 0.069555   -0.91940247]]\n",
      "###output######## [[0.930445   0.91940247]]\n",
      "**********************\n",
      "iteration: 49 :::: [[ 0.06950544 -0.91847034]]\n",
      "###output######## [[0.93049456 0.91847034]]\n",
      "**********************\n",
      "iteration: 5951 :::: [[ 0.02082056 -0.02234698]]\n",
      "###output######## [[0.97917944 0.02234698]]\n",
      "**********************\n",
      "iteration: 5952 :::: [[ 0.02081891 -0.02234494]]\n",
      "###output######## [[0.97918109 0.02234494]]\n",
      "**********************\n",
      "iteration: 5953 :::: [[ 0.02081726 -0.0223429 ]]\n",
      "###output######## [[0.97918274 0.0223429 ]]\n",
      "**********************\n",
      "iteration: 5954 :::: [[ 0.02081561 -0.02234086]]\n",
      "###output######## [[0.97918439 0.02234086]]\n",
      "**********************\n",
      "iteration: 5955 :::: [[ 0.02081396 -0.02233882]]\n",
      "###output######## [[0.97918604 0.02233882]]\n",
      "**********************\n",
      "iteration: 5956 :::: [[ 0.02081231 -0.02233678]]\n",
      "###output######## [[0.97918769 0.02233678]]\n",
      "**********************\n",
      "iteration: 5957 :::: [[ 0.02081067 -0.02233475]]\n",
      "###output######## [[0.97918933 0.02233475]]\n",
      "**********************\n",
      "iteration: 5958 :::: [[ 0.02080902 -0.02233271]]\n",
      "###output######## [[0.97919098 0.02233271]]\n",
      "**********************\n",
      "iteration: 5959 :::: [[ 0.02080737 -0.02233067]]\n",
      "###output######## [[0.97919263 0.02233067]]\n",
      "**********************\n",
      "iteration: 5960 :::: [[ 0.02080572 -0.02232864]]\n",
      "###output######## [[0.97919428 0.02232864]]\n",
      "**********************\n",
      "iteration: 5961 :::: [[ 0.02080408 -0.0223266 ]]\n",
      "###output######## [[0.97919592 0.0223266 ]]\n",
      "**********************\n",
      "iteration: 5962 :::: [[ 0.02080243 -0.02232457]]\n",
      "###output######## [[0.97919757 0.02232457]]\n",
      "**********************\n",
      "iteration: 5963 :::: [[ 0.02080079 -0.02232253]]\n",
      "###output######## [[0.97919921 0.02232253]]\n",
      "**********************\n",
      "iteration: 5964 :::: [[ 0.02079914 -0.0223205 ]]\n",
      "###output######## [[0.97920086 0.0223205 ]]\n",
      "**********************\n",
      "iteration: 5965 :::: [[ 0.0207975  -0.02231846]]\n",
      "###output######## [[0.9792025  0.02231846]]\n",
      "**********************\n",
      "iteration: 5966 :::: [[ 0.02079585 -0.02231643]]\n",
      "###output######## [[0.97920415 0.02231643]]\n",
      "**********************\n",
      "iteration: 5967 :::: [[ 0.02079421 -0.0223144 ]]\n",
      "###output######## [[0.97920579 0.0223144 ]]\n",
      "**********************\n",
      "iteration: 5968 :::: [[ 0.02079256 -0.02231237]]\n",
      "###output######## [[0.97920744 0.02231237]]\n",
      "**********************\n",
      "iteration: 5969 :::: [[ 0.02079092 -0.02231034]]\n",
      "###output######## [[0.97920908 0.02231034]]\n",
      "**********************\n",
      "iteration: 5970 :::: [[ 0.02078928 -0.02230831]]\n",
      "###output######## [[0.97921072 0.02230831]]\n",
      "**********************\n",
      "iteration: 5971 :::: [[ 0.02078763 -0.02230628]]\n",
      "###output######## [[0.97921237 0.02230628]]\n",
      "**********************\n",
      "iteration: 5972 :::: [[ 0.02078599 -0.02230425]]\n",
      "###output######## [[0.97921401 0.02230425]]\n",
      "**********************\n",
      "iteration: 5973 :::: [[ 0.02078435 -0.02230222]]\n",
      "###output######## [[0.97921565 0.02230222]]\n",
      "**********************\n",
      "iteration: 5974 :::: [[ 0.02078271 -0.02230019]]\n",
      "###output######## [[0.97921729 0.02230019]]\n",
      "**********************\n",
      "iteration: 5975 :::: [[ 0.02078107 -0.02229816]]\n",
      "###output######## [[0.97921893 0.02229816]]\n",
      "**********************\n",
      "iteration: 5976 :::: [[ 0.02077943 -0.02229613]]\n",
      "###output######## [[0.97922057 0.02229613]]\n",
      "**********************\n",
      "iteration: 5977 :::: [[ 0.02077779 -0.02229411]]\n",
      "###output######## [[0.97922221 0.02229411]]\n",
      "**********************\n",
      "iteration: 5978 :::: [[ 0.02077615 -0.02229208]]\n",
      "###output######## [[0.97922385 0.02229208]]\n",
      "**********************\n",
      "iteration: 5979 :::: [[ 0.02077451 -0.02229005]]\n",
      "###output######## [[0.97922549 0.02229005]]\n",
      "**********************\n",
      "iteration: 5980 :::: [[ 0.02077287 -0.02228803]]\n",
      "###output######## [[0.97922713 0.02228803]]\n",
      "**********************\n",
      "iteration: 5981 :::: [[ 0.02077123 -0.022286  ]]\n",
      "###output######## [[0.97922877 0.022286  ]]\n",
      "**********************\n",
      "iteration: 5982 :::: [[ 0.02076959 -0.02228398]]\n",
      "###output######## [[0.97923041 0.02228398]]\n",
      "**********************\n",
      "iteration: 5983 :::: [[ 0.02076795 -0.02228196]]\n",
      "###output######## [[0.97923205 0.02228196]]\n",
      "**********************\n",
      "iteration: 5984 :::: [[ 0.02076631 -0.02227993]]\n",
      "###output######## [[0.97923369 0.02227993]]\n",
      "**********************\n",
      "iteration: 5985 :::: [[ 0.02076468 -0.02227791]]\n",
      "###output######## [[0.97923532 0.02227791]]\n",
      "**********************\n",
      "iteration: 5986 :::: [[ 0.02076304 -0.02227589]]\n",
      "###output######## [[0.97923696 0.02227589]]\n",
      "**********************\n",
      "iteration: 5987 :::: [[ 0.0207614  -0.02227387]]\n",
      "###output######## [[0.9792386  0.02227387]]\n",
      "**********************\n",
      "iteration: 5988 :::: [[ 0.02075977 -0.02227185]]\n",
      "###output######## [[0.97924023 0.02227185]]\n",
      "**********************\n",
      "iteration: 5989 :::: [[ 0.02075813 -0.02226983]]\n",
      "###output######## [[0.97924187 0.02226983]]\n",
      "**********************\n",
      "iteration: 5990 :::: [[ 0.0207565  -0.02226781]]\n",
      "###output######## [[0.9792435  0.02226781]]\n",
      "**********************\n",
      "iteration: 5991 :::: [[ 0.02075486 -0.02226579]]\n",
      "###output######## [[0.97924514 0.02226579]]\n",
      "**********************\n",
      "iteration: 5992 :::: [[ 0.02075323 -0.02226377]]\n",
      "###output######## [[0.97924677 0.02226377]]\n",
      "**********************\n",
      "iteration: 5993 :::: [[ 0.02075159 -0.02226175]]\n",
      "###output######## [[0.97924841 0.02226175]]\n",
      "**********************\n",
      "iteration: 5994 :::: [[ 0.02074996 -0.02225973]]\n",
      "###output######## [[0.97925004 0.02225973]]\n",
      "**********************\n",
      "iteration: 5995 :::: [[ 0.02074833 -0.02225772]]\n",
      "###output######## [[0.97925167 0.02225772]]\n",
      "**********************\n",
      "iteration: 5996 :::: [[ 0.02074669 -0.0222557 ]]\n",
      "###output######## [[0.97925331 0.0222557 ]]\n",
      "**********************\n",
      "iteration: 5997 :::: [[ 0.02074506 -0.02225368]]\n",
      "###output######## [[0.97925494 0.02225368]]\n",
      "**********************\n",
      "iteration: 5998 :::: [[ 0.02074343 -0.02225167]]\n",
      "###output######## [[0.97925657 0.02225167]]\n",
      "**********************\n",
      "iteration: 5999 :::: [[ 0.0207418  -0.02224965]]\n",
      "###output######## [[0.9792582  0.02224965]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "inputNeurons=2 \n",
    "hiddenlayerNeurons=4 \n",
    "outputNeurons=2 \n",
    "iteration=6000\n",
    "\n",
    "input = np.random.randint(1,5,inputNeurons) \n",
    "output = np.array([1.0,0.0]) \n",
    "hidden_layer=np.random.rand(1,hiddenlayerNeurons)\n",
    "\n",
    "hidden_biass=np.random.rand(1,hiddenlayerNeurons) \n",
    "output_bias=np.random.rand(1,outputNeurons) \n",
    "hidden_weights=np.random.rand(inputNeurons,hiddenlayerNeurons) \n",
    "output_weights=np.random.rand(hiddenlayerNeurons,outputNeurons)\n",
    "\n",
    "def sigmoid (layer):\n",
    "    return 1/(1 + np.exp(-layer))\n",
    "\n",
    "\n",
    "def gradient(layer): \n",
    "    return layer*(1-layer)\n",
    "\n",
    "for i in range(iteration):\n",
    "\n",
    "    hidden_layer=np.dot(input,hidden_weights) \n",
    "    hidden_layer=sigmoid(hidden_layer+hidden_biass)\n",
    "\n",
    "    output_layer=np.dot(hidden_layer,output_weights) \n",
    "    output_layer=sigmoid(output_layer+output_bias)\n",
    "\n",
    "    error = (output-output_layer) \n",
    "    gradient_outputLayer=gradient(output_layer)\n",
    "    error_terms_output=gradient_outputLayer * error \n",
    "    error_terms_hidden=gradient(hidden_layer)*np.dot(error_terms_output,output_weights.T)\n",
    "\n",
    "    gradient_hidden_weights = np.dot(input.reshape(inputNeurons,1),error_terms_hidden.reshape(1,hiddenlayerNeurons))\n",
    "    gradient_ouput_weights = np.dot(hidden_layer.reshape(hiddenlayerNeurons,1),error_terms_output.reshape(1,outputNeurons))\n",
    "\n",
    "    hidden_weights = hidden_weights + 0.05*gradient_hidden_weights \n",
    "    output_weights = output_weights + 0.05*gradient_ouput_weights \n",
    "    if i<50 or i>iteration-50:\n",
    "        print(\"**********************\") \n",
    "        print(\"iteration:\",i,\"::::\",error) \n",
    "        print(\"###output########\",output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf6b602",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
